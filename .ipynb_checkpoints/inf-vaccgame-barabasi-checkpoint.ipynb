{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "'''\n",
    "Cvacc[i] = cost of vaccination for node i\n",
    "Cinf[i]: cost of infection for node i\n",
    "x[i]: current strategy of node i\n",
    "    x[i] = 1 ==> i is vaccinated\n",
    "S(x): set of vaccinated nodes\n",
    "comp(x): components formed by residual nodes\n",
    "cost[i]: cost of node i\n",
    "\n",
    "#Evaluating reduction in cost for node i\n",
    "#return old cost - new cost\n",
    "def reduction_in_cost(x, comp, cost, Cvacc, Cinf, i)\n",
    "    if x[i] == 0, then return  cost[i] - Cvacc[i]\n",
    "    if x[i] == 1\n",
    "        A = {comp(j, x): j is a nbr of i }\n",
    "        N = \\sum_{X in A} |X|\n",
    "        return  Cvacc[i] - N^2 Cinf[i]/n\n",
    "\n",
    "#best response\n",
    "def best_respose(Cvacc, Cinf)\n",
    "    xinit: random strategy\n",
    "    initialize comp, cost\n",
    "    for t = 1.. T:\n",
    "        for i in V:\n",
    "            if reduction_in_cost(x, i) > 0:\n",
    "                flip x[i]\n",
    "                update comp\n",
    "\n",
    "#possible efficiencies\n",
    "    #uniform Cvacc, Cinf setting\n",
    "        if there is a large comp X: check benefit of vaccination\n",
    "        if all comp are small: check benefit of not vaccinating\n",
    "'''\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "#import EoN\n",
    "import matplotlib.pyplot as plt\n",
    "import csv, random, pdb, sys\n",
    "from IPython.core.debugger import set_trace\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#each line: id1, id2\n",
    "def read_graph(fname):\n",
    "    G = nx.Graph()\n",
    "    fp_reader = csv.reader(open(fname), delimiter = ' ')\n",
    "    headers = next(fp_reader) \n",
    "    count = 0\n",
    "    for line in fp_reader:\n",
    "        if line[1] != line[2]: \n",
    "            G.add_edge(line[1], line[2])\n",
    "        count += 1\n",
    "        if count >= 1000:\n",
    "            break\n",
    "    return G\n",
    "\n",
    "#create components\n",
    "#x: strategy vector where x[i] = 1 means i is vaccinated\n",
    "def init_comp(G, x):\n",
    "\n",
    "    # comp_id: {node u: component_id i}; mapping of each node to it's current component id\n",
    "    # comp_len: {component_id i: length(int)}; mapping of component id to its length\n",
    "    # comp_d: {component_id i: list of node in ith component}\n",
    "    # max_comp_id: integer; each time we create a new component id so it will be helpful.\n",
    "    comp_id = {}; comp_len = {}; comp_d = {}; max_comp_id = 0\n",
    "    \n",
    "    H = nx.Graph()\n",
    "    for u in G.nodes(): \n",
    "        H.add_node(u)\n",
    "    for e in G.edges():\n",
    "        u = e[0]; v = e[1]\n",
    "        if x[u] == 0 and x[v] == 0: #both nodes unvacccinated\n",
    "            H.add_edge(u, v)\n",
    "    comp = nx.connected_components(H)\n",
    "    \n",
    "    for c in list(comp):\n",
    "        max_comp_id += 1\n",
    "        for u in c: \n",
    "            comp_id[u] = max_comp_id\n",
    "        comp_len[max_comp_id] = len(list(c))\n",
    "        comp_d[max_comp_id] = list(c)\n",
    "\n",
    "    return H, comp_d, comp_id, comp_len, max_comp_id\n",
    "\n",
    "def comp_cost(x, comp_id, comp_len, Cvacc, Cinf):\n",
    "    cost = {}\n",
    "    for i in x:\n",
    "        if x[i] == 1: \n",
    "            cost[i] = Cvacc[i]\n",
    "        else: \n",
    "            cost[i] = comp_len[comp_id[i]]*Cinf[i]/(len(x)+0.0)\n",
    "    return cost\n",
    "\n",
    "\n",
    "#return reduction in cost if node u flips its strategy\n",
    "def reduction_in_cost(G, x, comp_id, comp_len, cost, Cvacc, Cinf, u):\n",
    "    if x[u] == 0: \n",
    "        return  cost[u] - Cvacc[u]\n",
    "    if x[u] == 1:\n",
    "        nbr_comp = {}; z = 1\n",
    "        for v in G.neighbors(u): \n",
    "            if x[v] == 0: \n",
    "                nbr_comp[comp_id[v]] = 1\n",
    "        for j in nbr_comp: \n",
    "            z += comp_len[j]\n",
    "        return cost[u] - z*Cinf[u]/(len(x)+0.0)\n",
    "\n",
    "\n",
    "def check_NE(G, x, comp, comp_id, comp_len, cost, Cvacc, Cinf):\n",
    "    num_violated = 0\n",
    "    for u in G.nodes():\n",
    "        if reduction_in_cost(G, x, comp_id, comp_len, cost, Cvacc, Cinf, u) > 0: \n",
    "            num_violated += 1\n",
    "    return num_violated\n",
    "\n",
    "#remove node u and split its comp\n",
    "#use ids starting from comp_max_id + 1\n",
    "def remove_node(G, x, comp_d, comp_id, comp_len, comp_max_id, u):\n",
    "    \n",
    "    C = set(comp_d[comp_id[u]])\n",
    "    C.remove(u); \n",
    "    del comp_d[comp_id[u]]; \n",
    "    del comp_len[comp_id[u]]\n",
    "    comp_max_id += 1; comp_id[u] = comp_max_id; comp_d[comp_max_id] = [u]; comp_len[comp_max_id] = 1\n",
    "    H = nx.Graph()\n",
    "    for v in C: \n",
    "        H.add_node(v)\n",
    "    for v1 in C: \n",
    "        for v2 in G.neighbors(v1):\n",
    "            if v2 in C: H.add_edge(v1, v2)\n",
    "    comp1 = nx.connected_components(H)\n",
    "    comp = list(comp1).copy()\n",
    "    \n",
    "    for c in list(comp):\n",
    "        comp_max_id += 1\n",
    "        comp_d[comp_max_id] = list(c); comp_len[comp_max_id] = len(c)\n",
    "        for v in list(c): comp_id[v] = comp_max_id\n",
    "    return comp_d, comp_id, comp_len, comp_max_id\n",
    "\n",
    "#add node u and create comp\n",
    "def add_node(G, x, comp_d, comp_id, comp_len, comp_max_id, u):\n",
    "    Tu = comp_d[comp_id[u]].copy()\n",
    "    del comp_d[comp_id[u]]\n",
    "    del comp_len[comp_id[u]]\n",
    "    \n",
    "    comp_max_id += 1\n",
    "    S = set([u])\n",
    "\n",
    "    for v in G.neighbors(u):\n",
    "        if x[v] == 0: #v is not vaccinated\n",
    "            if comp_id[v] != comp_id[u] and comp_id[v] in comp_d:\n",
    "                T = set(comp_d[comp_id[v]].copy())\n",
    "            elif comp_id[v] == comp_id[u]:\n",
    "                T = set(Tu)\n",
    "            S = S | T\n",
    "            if comp_id[v] in comp_d: \n",
    "                del comp_d[comp_id[v]]\n",
    "                del comp_len[comp_id[v]]\n",
    "            for vprime in T: comp_id[vprime] = comp_max_id\n",
    "\n",
    "    #merge the components containing S into one\n",
    "    comp_id[u] = comp_max_id\n",
    "    comp_d[comp_max_id] = list(S)\n",
    "    comp_len[comp_max_id] = len(S)\n",
    "\n",
    "    return comp_d, comp_id, comp_len, comp_max_id\n",
    "            \n",
    "#flip strategy of node u\n",
    "def update_strategy(x, G, H, comp_d, comp_id, comp_len, cost, Cvacc, Cinf, comp_max_id, u):\n",
    "\n",
    "    if x[u] == 0:\n",
    "        x[u] = 1\n",
    "        comp_d, comp_id, comp_len, comp_max_id = remove_node(G, x, comp_d, \n",
    "                                                             comp_id, comp_len, comp_max_id, u)\n",
    "        cost[u] = Cvacc[u]\n",
    "        return x, comp_d, comp_id, comp_len, cost, comp_max_id\n",
    "\n",
    "    else: #x[u] = 1\n",
    "        x[u] = 0\n",
    "        comp_d, comp_id, comp_len, comp_max_id = add_node(G, x,\n",
    "                                                          comp_d, comp_id, comp_len, comp_max_id, u)\n",
    "        cost[u] = comp_len[comp_id[u]]*Cinf[u]/(len(x)+0.0)\n",
    "        return x, comp_d, comp_id, comp_len, cost, comp_max_id\n",
    "        \n",
    "def print_analysis(comp_id, comp_len): \n",
    "    component_ids = np.unique(list(comp_id.values()))  \n",
    "    component_lengths = [comp_len[i] for i in component_ids] \n",
    "    avg_comp_size = round(np.mean(component_lengths),2)\n",
    "    max_comp_size = np.max(component_lengths)\n",
    "    #print(\"Average component size: \", avg_comp_size)\n",
    "    #print(\"Max component size: \", max_comp_size) \n",
    "    return avg_comp_size, max_comp_size  \n",
    "\n",
    "#start at strategy x and run for T steps\n",
    "def best_response(G, Cvacc, Cinf, x, T, epsilon=0.05):\n",
    "    if len(x) == 0:\n",
    "        for u in G.nodes(): x[u] = np.random.randint(0, 2)\n",
    "    \n",
    "    H, comp_d, comp_id, comp_len, comp_max_id = init_comp(G, x)\n",
    "    #print('x', x)\n",
    "    cost = comp_cost(x, comp_id, comp_len, Cvacc, Cinf)\n",
    "    V = G.nodes(); itrn = 0\n",
    "    for t in range(T):\n",
    "        #u = random.choice(list(V)); \n",
    "        num_updated = 0\n",
    "        flag = {}\n",
    "\n",
    "        count = 0 \n",
    "        while count < len(V):\n",
    "            u = random.choice(list(V))\n",
    "            if u in flag:\n",
    "                continue\n",
    "\n",
    "            flag[u]= 1\n",
    "            count += 1\n",
    "#             itrn += 1\n",
    "#             if (itrn % 10 == 0): print(itrn)\n",
    "            if reduction_in_cost(G, x, comp_id, comp_len, cost, Cvacc, Cinf, u) > 0:\n",
    "                x, comp_d, comp_id, comp_len, cost, comp_max_id = update_strategy(x, \n",
    "                                    G, H, comp_d, comp_id, comp_len, cost, Cvacc, Cinf, comp_max_id, u)\n",
    "                num_updated += 1\n",
    "\n",
    "        if num_updated == 0:\n",
    "            print(\"times: \", t)\n",
    "            avg_comp_size, max_comp_size = print_analysis(comp_id, comp_len)\n",
    "            return x, check_NE(G, x, comp_d, comp_id, comp_len, cost, Cvacc, Cinf), avg_comp_size, max_comp_size, comp_id, comp_len, comp_d\n",
    "    \n",
    "    avg_comp_size, max_comp_size = print_analysis(comp_id, comp_len)\n",
    "    return x, check_NE(G, x, comp_d, comp_id, comp_len, cost, Cvacc, Cinf), avg_comp_size, max_comp_size, comp_id, comp_len, comp_d\n",
    "\n",
    "\n",
    "#start at strategy x and run for T steps\n",
    "def best_response_v2(G, Cvacc, Cinf, x, T, epsilon=0.05):\n",
    "    if len(x) == 0:\n",
    "        for u in G.nodes(): x[u] = np.random.randint(0, 2)\n",
    "    \n",
    "    H, comp_d, comp_id, comp_len, comp_max_id = init_comp(G, x)\n",
    "    #print('x', x)\n",
    "    cost = comp_cost(x, comp_id, comp_len, Cvacc, Cinf)\n",
    "    V = G.nodes(); itrn = 0\n",
    "    for t in range(T):\n",
    "        #u = random.choice(list(V)); \n",
    "        num_updated = 0\n",
    "        for u in G.nodes():\n",
    "#             itrn += 1\n",
    "#             if (itrn % 10 == 0): print(itrn)\n",
    "            num_updated += update_if_reduce(x, G, H, comp_d, comp_id, comp_len, \n",
    "                                            cost, Cvacc, Cinf, comp_max_id, u)\n",
    "        if num_updated <= epsilon*len(x): return x, num_updated\n",
    "    return x, num_updated\n",
    "\n",
    "def save_file(filename, data):\n",
    "    with open(filename, 'w') as f:\n",
    "        for row in data:\n",
    "            for item in row:\n",
    "                f.write(\"%s\\t\" % item)\n",
    "            f.write(\"\\n\")\n",
    "\n",
    "\n",
    "def save_degree_hist(comp_id, comp_len, comp_d, G, alpha):     \n",
    "    component_ids = np.unique(list(comp_id.values()))  \n",
    "    component_lengths = [comp_len[i] for i in component_ids] \n",
    "    index_max = np.argmax(component_lengths)\n",
    "    max_comp = component_ids[index_max]\n",
    "    max_comp_nodes = comp_d[max_comp]\n",
    "    max_nodes_degrees = [G.degree(node) for node in max_comp_nodes]\n",
    "    plt.hist(max_nodes_degrees, density=False, bins=20)  # `density=False` would make counts\n",
    "    plt.ylabel('Num of nodes')\n",
    "    plt.xlabel('Degree');\n",
    "    plt.title(\"Histogram of degrees for Max Component Nodes; alpha: \" + str(alpha) + \"; len: \" + str(len(max_comp_nodes)))\n",
    "    plt.savefig(\"../out/fig/max_comp_nodes_alpha_\" + str(alpha) + \".png\")\n",
    "    plt.show()\n",
    "\n",
    "def save_graph_data(comp_id, comp_len, comp_d, G):     \n",
    "    graph_data = {}\n",
    "    graph_data['comp_id'] = comp_id\n",
    "    graph_data['comp_len'] = comp_len\n",
    "    graph_data['comp_d'] = comp_d\n",
    "    graph_data['nodes'] = list(G.nodes())\n",
    "    graph_data['edges'] = list(G.edges())\n",
    "    graph_data['degree'] = dict(G.degree)\n",
    "    return graph_data\n",
    "\n",
    "\n",
    "\n",
    "def remove_topk_nodes(G, k):\n",
    "    degree_tup = list(dict(G.degree).items())\n",
    "    degree_tup = sorted(degree_tup, key=lambda x: -1*x[1])\n",
    "    top_k_nodes = [x for x,d in degree_tup[:k]]\n",
    "    G_res = copy.deepcopy(G)\n",
    "    for node in top_k_nodes:\n",
    "        G_res.remove_node(node)\n",
    "    \n",
    "    return G_res\n",
    "\n",
    "def inital_comp_size(G):\n",
    "    comp_id = {}; comp_len = {}; comp_d = {}; max_comp_id = 0\n",
    "    H = nx.Graph()\n",
    "    for u in G.nodes(): \n",
    "        H.add_node(u)\n",
    "        \n",
    "    for e in G.edges():\n",
    "        u = e[0]; v = e[1]\n",
    "        H.add_edge(u, v)\n",
    "    comp = nx.connected_components(H)\n",
    "\n",
    "    for c in list(comp):\n",
    "        for u in c: \n",
    "            comp_id[u] = max_comp_id\n",
    "        comp_len[max_comp_id] = len(list(c))\n",
    "        comp_d[max_comp_id] = list(c)\n",
    "        max_comp_id += 1\n",
    "        \n",
    "    return H, comp_d, comp_id, comp_len, max_comp_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "### run for a fixed network and fixed alpha\n",
    "##########################################\n",
    "    \n",
    "    T = 100\n",
    "    epsilon = 0.001\n",
    "\n",
    "    alphavals = 1.0/ np.arange(0.1, 1.0, 0.1)\n",
    "    #alphavals = sys.argv[1]\n",
    "\n",
    "\n",
    "    nlist = [10000, 10000]\n",
    "    mlist = [3, 4]\n",
    "\n",
    "    stack_num_vacc = []\n",
    "    stack_exp_inf = []\n",
    "\n",
    "    for n,m in zip(nlist, mlist):\n",
    "        avg_file_name = './vacc_albemarle_household_1_7_dec7_avg.txt'\n",
    "        raw_file_name = './vacc_albemarle_household_1_7_dec7_raw.txt' \n",
    "        \n",
    "        raw_data = []\n",
    "        num_times = 10 ### vary\n",
    "        np.random.seed(0)\n",
    "\n",
    "\n",
    "        G = nx.barabasi_albert_graph(n, m)\n",
    "        n = len(G.nodes())\n",
    "        print(\"Original G num_edges:\", len(G.edges()), \" num_nodes:\", len(G.nodes()))\n",
    "        \n",
    "        # Remove k nodes with highest degree. Create a dictionary of {k: max_component_size} to check \n",
    "        # which k should be chosen to initialise the graph\n",
    "        k_max_comp_dict = {}\n",
    "\n",
    "        #k percent \n",
    "        for k in range(99):\n",
    "            k_node = int(k/100*len(G.nodes()))\n",
    "            G_res = remove_topk_nodes(G, k_node ) # removes k% node here\n",
    "            H, comp_d, comp_id, comp_len, comp_max_id = inital_comp_size(G_res) # find the comp details of the residual graph\n",
    "            avg_comp_size, max_comp_size = print_analysis(comp_id, comp_len) #nothing very important\n",
    "            k_max_comp_dict[k] = max_comp_size            \n",
    "        \n",
    "        print(\"Done k_max_comp_dict\")\n",
    "\n",
    "        times = 1\n",
    "        total_graph_data = {}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        n_num_vacc_list = []\n",
    "        n_exp_inf_list = []\n",
    "\n",
    "        for i in range(num_times):\n",
    "            num_vacc_list = []\n",
    "            exp_inf_list = []\n",
    "            for ind, alpha in enumerate(alphavals):\n",
    "                # Choose k for a given alpha such that max_comp_size < n/alpha\n",
    "                for k, max_comp_size in k_max_comp_dict.items():\n",
    "                    if max_comp_size < n/alpha:\n",
    "                        k_node = int(k/100*len(G.nodes()))\n",
    "                        G_res = remove_topk_nodes(G, k_node )\n",
    "                        break\n",
    "                \n",
    "                print(\"alpha: \", alpha, \"Top k: \", k, \"max_comp_size :\", max_comp_size, \"Num of nodes: \", len(G_res.nodes), \"Num of edges: \", len(G_res.edges))\n",
    "                # Initialize graph by removing top k nodes\n",
    "\n",
    "\n",
    "                x = {}; Cvacc = {}; Cinf = {}; #alpha = 10\n",
    "                for u in G.nodes():\n",
    "                    x[u] = 1 #np.random.randint(0, 2)\n",
    "                    Cvacc[u] = 1; \n",
    "                    Cinf[u] = Cvacc[u]*float(alpha)\n",
    "                    \n",
    "                for u in G_res.nodes():\n",
    "                    x[u] = 0 #np.random.randint(0, 2)\n",
    "\n",
    "                ## I'm guessing 1 means vaccinated and 0 means antivaxx\n",
    "                    \n",
    "                #T = 500\n",
    "                pre_vacc_nodes = len([i for i in x if x[i] == 1])\n",
    "                x, nviol, avg_comp_size, max_comp_size, comp_id, comp_len, comp_d = best_response(G, Cvacc, Cinf, x, T, epsilon)\n",
    "                num_vacc_nodes = len([i for i in x if x[i] == 1])\n",
    "                temp = [alpha, times, avg_comp_size, max_comp_size, num_vacc_nodes, pre_vacc_nodes]\n",
    "                raw_data.append(temp)\n",
    "                \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                num_vacc_list.append(num_vacc_nodes)\n",
    "                # print(comp_d)\n",
    "                exp_infection = 0\n",
    "                for i in comp_d:\n",
    "                    exp_infection += len(comp_d[i])*len(comp_d[i])\n",
    "                exp_inf_list.append(exp_infection/n)\n",
    "\n",
    "                print(\"alpha: \", alpha, \"Percent voilated: \", nviol/len(x), \"Num of vaccinated nodes: \", num_vacc_nodes, \"pre_vacc_nodes: \", pre_vacc_nodes)\n",
    "                print(\"avg_comp_size: \", avg_comp_size, \"max_comp_size: \",  max_comp_size, \"\\n\")\n",
    "                graph_data = save_graph_data(comp_id, comp_len, comp_d, G)\n",
    "                #save_degree_hist(comp_id, comp_len, comp_d, G, alpha)\n",
    "                total_graph_data[alpha] = graph_data\n",
    "\n",
    "                save_file(raw_file_name, raw_data)\n",
    "                #np.save('../out/total_graph_data.npy', total_graph_data) # save\n",
    "                #sys.stdout.flush()\n",
    "            \n",
    "            n_num_vacc_list.append(num_vacc_list)\n",
    "            n_exp_inf_list.append(exp_inf_list)\n",
    "        \n",
    "\n",
    "        n_num_vacc_list = np.array(n_num_vacc_list)\n",
    "        n_exp_inf_list = np.array(n_exp_inf_list)\n",
    "\n",
    "\n",
    "        vacc_mean = n_num_vacc_list.mean(axis = 0)\n",
    "        vacc_std = n_num_vacc_list.std(axis = 0)\n",
    "\n",
    "        exp_inf_mean = n_exp_inf_list.mean(axis = 0)\n",
    "        exp_inf_std = n_exp_inf_list.std(axis = 0)\n",
    "        \n",
    "        stack_num_vacc.append(vacc_mean)\n",
    "        stack_exp_inf.append(exp_inf_mean)\n",
    "\n",
    "\n",
    "        c_by_alpha = [1/a for a in alphavals]\n",
    "\n",
    "    for num_vacc_list in stack_num_vacc:\n",
    "        plt.plot(c_by_alpha, num_vacc_list)\n",
    "        plt.xlabel(r'$C_{vacc}/C_{inf}$')\n",
    "        plt.ylabel(\"#vacc\")\n",
    "\n",
    "    plt.legend([\"n=\"+str(n)+ \",m=\"+str(m) for n,m in zip(nlist,mlist)])\n",
    "    plt.show()\n",
    "\n",
    "    for exp_inf_list in stack_exp_inf:\n",
    "        plt.plot(c_by_alpha, exp_inf_list)\n",
    "        plt.xlabel(r'$C_{vacc}/C_{inf}$')\n",
    "        plt.ylabel(\"E[#infection]\")\n",
    "    \n",
    "    plt.legend([\"n=\"+str(n)+ \",m=\"+str(m) for n,m in zip(nlist,mlist)])\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "    ## normalized\n",
    "    i = 0\n",
    "    for num_vacc_list in stack_num_vacc:\n",
    "        num_vacc_list = np.array(num_vacc_list) / nlist[i]\n",
    "        i += 1\n",
    "\n",
    "        plt.plot(c_by_alpha, num_vacc_list)\n",
    "        plt.xlabel(r'$C_{vacc}/C_{inf}$')\n",
    "        plt.ylabel(\"#vacc/n\")\n",
    "\n",
    "    plt.legend([\"n=\"+str(n)+ \",m=\"+str(m) for n,m in zip(nlist,mlist)])\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "    i = 0\n",
    "    for exp_inf_list in stack_exp_inf:\n",
    "        exp_inf_list = np.array(exp_inf_list) / nlist[i]\n",
    "        i += 1\n",
    "\n",
    "        plt.plot(c_by_alpha, exp_inf_list)\n",
    "        plt.xlabel(r'$C_{vacc}/C_{inf}$')\n",
    "        plt.ylabel(\"E[#infection]/n\")\n",
    "    \n",
    "    plt.legend([\"n=\"+str(n)+ \",m=\"+str(m) for n,m in zip(nlist,mlist)])\n",
    "    plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
